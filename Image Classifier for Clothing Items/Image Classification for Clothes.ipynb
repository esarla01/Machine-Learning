{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS-NWR8oiDUi"
      },
      "source": [
        "# Image Recognition (PART A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2ju4kzflALe"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhW-x0QWk-6w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.linear_model\n",
        "import sklearn.pipeline\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# import plotting libraries\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set('notebook', font_scale=1.25, style='whitegrid')\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8bpbftxJ1zp"
      },
      "source": [
        "### Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JbOSyu1JyJC",
        "outputId": "b82276b8-fde7-40eb-dd8c-9c21b265e12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contents of train_x.csv: arr of shape (2102, 784)\n",
            "Contents of valid_x.csv: arr of shape (600, 784)\n",
            "Contents of train_x.csv: arr of shape (2102, 2)\n",
            "Contents of valid_x.csv: arr of shape (600, 2)\n",
            "Contents of test_x.csv: arr of shape (600, 2) \n",
            "\n",
            "Class Counts: training data\n",
            "sandal      800\n",
            "sneaker     800\n",
            "dress       400\n",
            "pullover    100\n",
            "top           1\n",
            "trouser       1\n",
            "Name: class_name, dtype: int64\n",
            "\n",
            "\n",
            "Class Counts: validation data\n",
            "dress       100\n",
            "trouser     100\n",
            "sandal      100\n",
            "top         100\n",
            "pullover    100\n",
            "sneaker     100\n",
            "Name: class_name, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_dir = os.path.abspath(\"data_fashion/\")\n",
        "# Load data\n",
        "train_x = pd.read_csv(os.path.join(data_dir, \"x_train.csv\")).to_numpy()\n",
        "train_y_df = pd.read_csv(os.path.join(data_dir, \"y_train.csv\"))\n",
        "valid_x = pd.read_csv(os.path.join(data_dir, \"x_valid.csv\")).to_numpy()\n",
        "valid_y_df = pd.read_csv(os.path.join(data_dir, \"y_valid.csv\"))\n",
        "test_x = pd.read_csv(os.path.join(data_dir, \"x_test.csv\")).to_numpy()\n",
        "\n",
        "# Print shapes\n",
        "for label, arr in [('train', train_x), ('valid', valid_x)]:\n",
        "    print(\"Contents of %s_x.csv: arr of shape %s\" % (\n",
        "        label, str(arr.shape)))\n",
        "\n",
        "for label, arr in [('train', train_y_df), ('valid', valid_y_df)]:\n",
        "    print(\"Contents of %s_x.csv: arr of shape %s\" % (\n",
        "        label, str(arr.shape)))\n",
        "\n",
        "print(\"Contents of test_x.csv: arr of shape %s \\n\" % (\n",
        "         str(arr.shape)))\n",
        "\n",
        "class_counts_train = train_y_df['class_name'].value_counts()\n",
        "class_counts_valid = valid_y_df['class_name'].value_counts()\n",
        "\n",
        "print(\"Class Counts: training data\")\n",
        "print(class_counts_train)\n",
        "print('\\n')\n",
        "print(\"Class Counts: validation data\")\n",
        "print(class_counts_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu3uh8tBil8S"
      },
      "source": [
        "### Pack Training and validation sets into big arrays (for sklearn hyperparameter search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tBypt8i2XGt",
        "outputId": "ecab5c64-0301-45cf-b3ae-8b32d16eede7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2702, 784)\n",
            "(2702, 1)\n"
          ]
        }
      ],
      "source": [
        "xall_LF = np.vstack([train_x, valid_x])\n",
        "yall_L = np.vstack([train_y_df[['class_name']], valid_y_df[['class_name']]])\n",
        "\n",
        "print(xall_LF.shape)\n",
        "print(yall_L.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emdJlO6r2XGu"
      },
      "outputs": [],
      "source": [
        "valid_indicators_L = np.hstack([\n",
        "    -1 * np.ones(train_y_df[['class_name']].size),\n",
        "    0 * np.ones(valid_y_df[['class_name']].size)\n",
        "])\n",
        "\n",
        "valid_indicators_L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOE34OEA2XGu"
      },
      "outputs": [],
      "source": [
        "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_L)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1kA9ND_2XGu"
      },
      "source": [
        "### Perform Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94bnQ6ri2XGu"
      },
      "outputs": [],
      "source": [
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'alpha': np.logspace(-6, 6, 12),\n",
        "    'learning_rate': ['constant', 'adaptive'],\n",
        "    'batch_size': [64, 128, 256, 512]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSLAt-Q2iqoE"
      },
      "outputs": [],
      "source": [
        "# Create a mlp model for classification\n",
        "clf = MLPClassifier(activation='relu', hidden_layer_sizes=100, max_iter=1000)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, scoring='balanced_accuracy',\n",
        "                           cv=my_splitter, refit=False, return_train_score=True)\n",
        "\n",
        "#Run Grid Search\n",
        "grid_search.fit(xall_LF, yall_L.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbxWmDZW2XGv"
      },
      "outputs": [],
      "source": [
        "grid_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRwoMdST2XGv"
      },
      "outputs": [],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX8_L3p8gbAV"
      },
      "outputs": [],
      "source": [
        "cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "print(cv_results_df)\n",
        "\n",
        "file_path = \"cv_results.csv\"\n",
        "cv_results_df.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvto6QI2XGv"
      },
      "source": [
        "### Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNtTn69o2XGw"
      },
      "outputs": [],
      "source": [
        "# Get best model from grid search\n",
        "mlp_best = MLPClassifier(activation='relu', hidden_layer_sizes=100, max_iter=1000,\n",
        "                         alpha=1e-06, batch_size=64, learning_rate='constant')\n",
        "\n",
        "mlp_best.fit(train_x, train_y_df['class_name'].values)\n",
        "\n",
        "# Get predictions from validation set\n",
        "yhat_valid = mlp_best.predict(valid_x)\n",
        "\n",
        "# Convert valid data to numpy array\n",
        "y_valid = valid_y_df['class_name'].values\n",
        "\n",
        "print(y_valid.shape)\n",
        "print(yhat_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv4yFa8o2XGw"
      },
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "confusion_matrix(y_valid, yhat_valid, labels=[\"dress\", \"pullover\", \"top\", \"trouser\", \"sandal\", \"sneaker\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF_TavxQ2XGw"
      },
      "source": [
        "### Training Set Modification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX-_KMgM2XGw",
        "outputId": "1443745f-fa29-4986-dd11-aa65f59cd329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4800\n",
            "4800\n"
          ]
        }
      ],
      "source": [
        "# Contents of train_x.csv: arr of shape (2102, 784)\n",
        "\n",
        "'''\n",
        "Contents of valid_x.csv: arr of shape (600, 2)\n",
        "sandal      800\n",
        "sneaker     800\n",
        "dress       400\n",
        "pullover    100\n",
        "top           1\n",
        "trouser       1\n",
        "'''\n",
        "y_train = train_y_df['class_name'].values\n",
        "modified_x_train = []\n",
        "modified_y_train = []\n",
        "\n",
        "for i in range(2102):\n",
        "    if(y_train[i] == \"pullover\"):\n",
        "        for a in range(8):\n",
        "            modified_x_train.append(train_x[i])\n",
        "            modified_y_train.append(y_train[i])\n",
        "\n",
        "    if (y_train[i] == \"dress\"):\n",
        "        for b in range(2):\n",
        "            modified_x_train.append(train_x[i])\n",
        "            modified_y_train.append(y_train[i])\n",
        "\n",
        "    if((y_train[i] == \"top\") or (y_train[i] == \"trouser\")):\n",
        "        for c in range(800):\n",
        "            modified_x_train.append(train_x[i])\n",
        "            modified_y_train.append(y_train[i])\n",
        "\n",
        "    if((y_train[i] == \"sandal\") or (y_train[i] == \"sneaker\")):\n",
        "        modified_x_train.append(train_x[i])\n",
        "        modified_y_train.append(y_train[i])\n",
        "\n",
        "\n",
        "\n",
        "print(len(modified_x_train))\n",
        "print(len(modified_y_train))\n",
        "\n",
        "modified_y_train_df = pd.DataFrame(modified_y_train, columns=['class_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5YEwfRB2XGx"
      },
      "source": [
        "### Pack Training and validation sets into big arrays (for sklearn hyperparameter search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn-3ps-y2XGx",
        "outputId": "46803613-8f36-4c9c-c4b9-5ecda916137b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5400, 784)\n",
            "(5400, 1)\n"
          ]
        }
      ],
      "source": [
        "xall_LF_2 = np.vstack([modified_x_train, valid_x])\n",
        "yall_L_2 = np.vstack([modified_y_train_df, valid_y_df[['class_name']]])\n",
        "\n",
        "print(xall_LF_2.shape)\n",
        "print(yall_L_2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lcy6ZFF2XGx"
      },
      "outputs": [],
      "source": [
        "valid_indicators_L_2 = np.hstack([\n",
        "    -1 * np.ones(modified_y_train_df.size),\n",
        "    0 * np.ones(valid_y_df[['class_name']].size)\n",
        "])\n",
        "\n",
        "valid_indicators_L_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLUT5BV42XGx"
      },
      "outputs": [],
      "source": [
        "my_splitter_2 = sklearn.model_selection.PredefinedSplit(valid_indicators_L_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yzEJffp2XGx"
      },
      "outputs": [],
      "source": [
        "#parameter grid\n",
        "param_grid_2 = {\n",
        "    'activation': ['logistic', 'relu'],\n",
        "    'alpha': np.logspace(-6, 6, 12),\n",
        "    'learning_rate': ['constant', 'adaptive'],\n",
        "    'batch_size': [64, 128, 256, 512]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n62Rp552XGy"
      },
      "outputs": [],
      "source": [
        "# Create a mlp model for classification\n",
        "clf_2 = MLPClassifier(hidden_layer_sizes=100, max_iter=1000)\n",
        "\n",
        "grid_search_2 = GridSearchCV(clf_2, param_grid_2, scoring='balanced_accuracy',\n",
        "                           cv=my_splitter_2, refit=False, return_train_score=True)\n",
        "\n",
        "#Run Grid Search\n",
        "grid_search_2.fit(xall_LF_2, yall_L_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT2BBiBg2XGy"
      },
      "outputs": [],
      "source": [
        "grid_search_2.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "FewaS1V92XGy"
      },
      "outputs": [],
      "source": [
        "grid_search_2.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrJ5pTkY2XGy",
        "outputId": "738b0e7d-e7e7-4243-d308-f38e544c0e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(600,)\n",
            "(600,)\n"
          ]
        }
      ],
      "source": [
        "# Get best model from grid search\n",
        "mlp_best_2 =  MLPClassifier(activation='relu', hidden_layer_sizes=100, max_iter=1000,\n",
        "                         alpha=533.6699231206302, batch_size=64, learning_rate='adaptive')\n",
        "\n",
        "mlp_best_2.fit(modified_x_train, modified_y_train)\n",
        "\n",
        "# Get predictions from validation set\n",
        "yhat_valid_2 = mlp_best_2.predict(valid_x)\n",
        "\n",
        "# Convert valid data to numpy array\n",
        "y_valid = valid_y_df['class_name'].values\n",
        "\n",
        "print(y_valid.shape)\n",
        "print(yhat_valid.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmbeOEZy2XGy"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_valid, yhat_valid_2, labels=[\"dress\", \"pullover\", \"top\", \"trouser\", \"sandal\", \"sneaker\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO-dWfJv2XGz"
      },
      "source": [
        "### Performance on Test Set via Leaderboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84JL0mul2XGz"
      },
      "outputs": [],
      "source": [
        "yhat_test = mlp_best_2.predict(test_x)\n",
        "\n",
        "# Define the file path where you want to save the CSV file\n",
        "# file_path = 'yproba1_test.txt'\n",
        "\n",
        "# Save the 'positive_prob' array as a CSV file\n",
        "np.savetxt('yhat_valid_2.txt', yhat_test, delimiter='\\n', fmt='%s')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8oo941a2XGz"
      },
      "source": [
        "### Image Recognition (PART B)\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiGHA-OX2XGz"
      },
      "outputs": [],
      "source": [
        "import skimage as ski"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAKtnlj42XGz",
        "outputId": "869688eb-6307-46fa-a134-e2f29cd65883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(784,)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n"
          ]
        }
      ],
      "source": [
        "from skimage.transform import rotate, rescale, warp, AffineTransform\n",
        "\n",
        "\n",
        "print(type(train_x[0]))\n",
        "print(train_x[0].shape)\n",
        "\n",
        "\n",
        "reshaped_image = np.reshape(train_x[0], (28, 28))\n",
        "print(reshaped_image.shape)\n",
        "\n",
        "# Rotions\n",
        "# Rotate 45\n",
        "# Rotate 90\n",
        "# Rotate 180\n",
        "# Rotate 270\n",
        "rotated_image = rotate(reshaped_image, 45)\n",
        "print(rotated_image.shape)\n",
        "\n",
        "# # Rescale (Blurring)\n",
        "# # Rescale 2.0 x 0.5\n",
        "# # Rescale 0.5 x 2.0\n",
        "# rescaled_image = rescale(reshaped_image, 0.5)\n",
        "# rescaled_image = rescale(rescaled_image, 2.0)\n",
        "# print(rescaled_image.shape)\n",
        "\n",
        "\n",
        "# Translation\n",
        "# Translate (-2, 0)\n",
        "# Translate (0, 2)\n",
        "translation = AffineTransform(translation=(-2, -2))  # Shift 10 pixels left and 10 pixels up\n",
        "translated_image = warp(reshaped_image, translation)\n",
        "print(translated_image.shape)\n",
        "\n",
        "# Horizontal Flip\n",
        "# Vertical Flip\n",
        "flipped_image_horizontal = reshaped_image[:, ::-1].copy()\n",
        "flipped_image_vertical = reshaped_image[::-1, :].copy()\n",
        "print(flipped_image_horizontal.shape)\n",
        "print(flipped_image_vertical.shape)\n",
        "\n",
        "\n",
        "\n",
        "# plt.imshow(reshaped_image, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT6jI-dM2XG0"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(flipped_image_horizontal, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxYjNb3O2XG0"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(flipped_image_vertical, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EBw21bs2XG0"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(translated_image, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb9GFa1O2XG1"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(rescaled_image, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXmyPMtQ2XG1"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(rotated_image, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obh7qotu2XG1"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def rotate_image(image):\n",
        "    angle = random.choice([45, 90, 180, 270])\n",
        "    return rotate(image, angle)\n",
        "\n",
        "def translate_image(image):\n",
        "    translation = random.choice([(-2, 0), (0, 2), (3, 3), (-3, 0)])\n",
        "    transform = AffineTransform(translation=translation)\n",
        "    return warp(image, transform)\n",
        "\n",
        "def flip_horizontal(image):\n",
        "    return image[:, ::-1]\n",
        "\n",
        "def flip_vertical(image):\n",
        "    return image[::-1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkECTraG2XG2"
      },
      "outputs": [],
      "source": [
        "augmented_xall_LF_2 = []\n",
        "augmented_yall_L_2 = []\n",
        "\n",
        "\n",
        "for i in range(len(modified_x_train)):\n",
        "\n",
        "    curr_image = modified_x_train[i]\n",
        "    curr_label = modified_y_train[i]\n",
        "\n",
        "    # Original image\n",
        "    reshaped_image = np.reshape(curr_image, (28, 28))\n",
        "    augmented_xall_LF_2.append(reshaped_image)\n",
        "    augmented_yall_L_2.append(curr_label)\n",
        "\n",
        "     # Randomly choose one augmentation technique\n",
        "    augmentation_function = random.choice([translate_image, flip_horizontal])\n",
        "    augmented_image = augmentation_function(reshaped_image)\n",
        "\n",
        "    # Append the augmented image and label\n",
        "    augmented_xall_LF_2.append(augmented_image)\n",
        "    augmented_yall_L_2.append(curr_label)\n",
        "\n",
        "for i in range(len(augmented_xall_LF_2)):\n",
        "    augmented_xall_LF_2[i] = np.reshape(augmented_xall_LF_2[i], (784, ))\n",
        "\n",
        "augmented_xall_LF_2 = np.array(augmented_xall_LF_2)\n",
        "augmented_yall_L_2 = pd.DataFrame(augmented_yall_L_2, columns=['classname'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPeaGlEn2XG2",
        "outputId": "d63fe037-70b7-41ce-ae6e-a9cb1775a57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10200, 784)\n",
            "(10200, 1)\n"
          ]
        }
      ],
      "source": [
        "xall_LF_3 = np.vstack([augmented_xall_LF_2, valid_x])\n",
        "yall_L_3 = np.vstack([augmented_yall_L_2, valid_y_df[['class_name']]])\n",
        "\n",
        "print(xall_LF_3.shape)\n",
        "print(yall_L_3.shape)\n",
        "\n",
        "valid_indicators_L_3 = np.hstack([\n",
        "    -1 * np.ones(modified_y_train_df.size),\n",
        "    0 * np.ones(valid_y_df[['class_name']].size)\n",
        "])\n",
        "\n",
        "my_splitter_3 = sklearn.model_selection.PredefinedSplit(valid_indicators_L_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1jq-3Ub2XG2"
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buH3U8YA2XG2"
      },
      "outputs": [],
      "source": [
        "# Parameter grid\n",
        "param_grid = {\n",
        "    'alpha': np.logspace(-2, 2, 4),\n",
        "    'learning_rate': ['constant', 'adaptive'],\n",
        "    'batch_size': [64, 128]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejlxPRMr2XG3",
        "outputId": "bca14fda-0eb6-4657-a972-64e4875ac23b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             estimator=MLPClassifier(early_stopping=True,\n",
              "                                     hidden_layer_sizes=100, max_iter=1000),\n",
              "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-02, 2.15443469e-01, 4.64158883e+00, 1.00000000e+02]),\n",
              "                         &#x27;batch_size&#x27;: [64, 128],\n",
              "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;]},\n",
              "             refit=False, return_train_score=True, scoring=&#x27;balanced_accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             estimator=MLPClassifier(early_stopping=True,\n",
              "                                     hidden_layer_sizes=100, max_iter=1000),\n",
              "             param_grid={&#x27;alpha&#x27;: array([1.00000000e-02, 2.15443469e-01, 4.64158883e+00, 1.00000000e+02]),\n",
              "                         &#x27;batch_size&#x27;: [64, 128],\n",
              "                         &#x27;learning_rate&#x27;: [&#x27;constant&#x27;, &#x27;adaptive&#x27;]},\n",
              "             refit=False, return_train_score=True, scoring=&#x27;balanced_accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=100, max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=100, max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             estimator=MLPClassifier(early_stopping=True,\n",
              "                                     hidden_layer_sizes=100, max_iter=1000),\n",
              "             param_grid={'alpha': array([1.00000000e-02, 2.15443469e-01, 4.64158883e+00, 1.00000000e+02]),\n",
              "                         'batch_size': [64, 128],\n",
              "                         'learning_rate': ['constant', 'adaptive']},\n",
              "             refit=False, return_train_score=True, scoring='balanced_accuracy')"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a mlp model for classification\n",
        "clf = MLPClassifier(activation='relu', hidden_layer_sizes=100, max_iter=1000, early_stopping = True)\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, scoring='balanced_accuracy',\n",
        "                           cv=my_splitter_3, refit=False, return_train_score=True)\n",
        "\n",
        "#Run Grid Search\n",
        "grid_search.fit(augmented_xall_LF_2, augmented_yall_L_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qoEyqxC2XG3",
        "outputId": "3055629a-6106-4133-ae18-22a2a51aaa05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tanviamrit/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=533.6699231206302, batch_size=64, hidden_layer_sizes=100,\n",
              "              learning_rate=&#x27;adaptive&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=533.6699231206302, batch_size=64, hidden_layer_sizes=100,\n",
              "              learning_rate=&#x27;adaptive&#x27;, max_iter=1000)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(alpha=533.6699231206302, batch_size=64, hidden_layer_sizes=100,\n",
              "              learning_rate='adaptive', max_iter=1000)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_3 =  MLPClassifier(activation='relu', hidden_layer_sizes=100, max_iter=1000,\n",
        "                         alpha=533.6699231206302, batch_size=64, learning_rate='adaptive')\n",
        "\n",
        "clf_3.fit(augmented_xall_LF_2, augmented_yall_L_2)\n",
        "\n",
        "yhat_valid_3 = clf_3.predict(valid_x)\n",
        "\n",
        "bal_acc = sklearn.metrics.balanced_accuracy_score(y_valid, yhat_valid_3)\n",
        "bal_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9gfocLn2XG3",
        "outputId": "3a8f0075-8303-47a8-b91c-e58d8873ba7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7475"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdAJus4e2XG3",
        "outputId": "0e04aac0-b4be-426a-bfa6-5dd9923fddb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'alpha': 0.0001519911082952933, 'batch_size': 64, 'learning_rate': 'adaptive'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zLaY4E62XG3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}